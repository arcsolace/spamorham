{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamOrHam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwmBAsk59Vbz"
      },
      "source": [
        "Hello! This is the notebook code for a group project which I created for a Data Science course I took. In this code, we used a publicly available dataset of 5,572 text messages taken from Kaggle, and the aim was to use Naive Bayes in order to model and predict spam messages in text.\n",
        "\n",
        "The first step below is to download the dataset, which has been saved as a .csv for easier download from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG5dljIphzfk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6248e402-ba85-4178-a29c-6f7588ad43f9"
      },
      "source": [
        "!gdown --id 1htegPIcvPH_maI2nP0bQjauzHLwYlJQO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1htegPIcvPH_maI2nP0bQjauzHLwYlJQO\n",
            "To: /content/spam.csv\n",
            "\r  0% 0.00/504k [00:00<?, ?B/s]\r100% 504k/504k [00:00<00:00, 56.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BaPEXDz9_IE"
      },
      "source": [
        "The first step is to take a look at the dataset, of course!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjQmH-zEh58j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "66f69c71-d82e-4931-c906-4578a6fcdb47"
      },
      "source": [
        "import pandas as pd\n",
        "sms = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
        "sms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        v1  ... Unnamed: 4\n",
              "0      ham  ...        NaN\n",
              "1      ham  ...        NaN\n",
              "2     spam  ...        NaN\n",
              "3      ham  ...        NaN\n",
              "4      ham  ...        NaN\n",
              "...    ...  ...        ...\n",
              "5567  spam  ...        NaN\n",
              "5568   ham  ...        NaN\n",
              "5569   ham  ...        NaN\n",
              "5570   ham  ...        NaN\n",
              "5571   ham  ...        NaN\n",
              "\n",
              "[5572 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbqrpcs3-F7P"
      },
      "source": [
        "There are a lot of NaN values and extra columns, so those extra columns need to be dropped, as well as the existing columns renamed for easier referencing.\n",
        "\n",
        "Below, we can see that there are 4825 legitimate messages, and 747 spam messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TusHMu0iOhk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "099cdd7c-9811-4f92-cf22-bd62e69f2799"
      },
      "source": [
        "sms.dropna(inplace = True, axis = 1)\n",
        "sms.columns = [\"label\", \"msg\"]\n",
        "sms.groupby(\"label\").describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">msg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>4825</td>\n",
              "      <td>4516</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>747</td>\n",
              "      <td>653</td>\n",
              "      <td>Please call our customer service representativ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        msg                                                               \n",
              "      count unique                                                top freq\n",
              "label                                                                     \n",
              "ham    4825   4516                             Sorry, I'll call later   30\n",
              "spam    747    653  Please call our customer service representativ...    4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA340NV0-hHu"
      },
      "source": [
        "First, we create a nominal binary scale to code for ham or spam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz6hfXasi-s1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "431757c2-699e-4010-a1d6-fc6efba97bd7"
      },
      "source": [
        "sms[\"label_sign\"] = sms.label.map({\"ham\" : 0, \"spam\" : 1})\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>label_sign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                msg  label_sign\n",
              "0   ham  Go until jurong point, crazy.. Available only ...           0\n",
              "1   ham                      Ok lar... Joking wif u oni...           0\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...           1\n",
              "3   ham  U dun say so early hor... U c already then say...           0\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4BmIYgh-osP"
      },
      "source": [
        "Using the NLTK NLP library, the stopwords and punctuation are removed below. This is so there is no interference created by the inclusion of stopwords and punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B5L0TdSms0m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3b93fca-e46b-4890-aa71-5b59333c0ec0"
      },
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "mess = \"Nah I don't think he goes to usf, he lives around here though\";\n",
        "nopunc = [char for char in mess if char not in string.punctuation]\n",
        "nopunc = ''.join(nopunc)\n",
        "nopunc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nah I dont think he goes to usf he lives around here though'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn1uArZc_Edr"
      },
      "source": [
        "After punctuation is removed, the words in each sentence are tokenized using a simple text split method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3bTHjKZpwNC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f18c4248-223b-40ef-ee2d-9c421982684e"
      },
      "source": [
        "word_tokens = nopunc.split()\n",
        "stopwords_ac =  stopwords.words('english')\n",
        "filtered_sentence = []\n",
        "for w in word_tokens: \n",
        "    if w not in stopwords_ac: \n",
        "        filtered_sentence.append(w) \n",
        "\n",
        "print(filtered_sentence)\n",
        "\n",
        "def clean_word(mess):\n",
        "    nopunc = [char for char in mess if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    word_tokens = nopunc.split()\n",
        "    stopwords_ac =  stopwords.words('english')\n",
        "    filtered_sentence = []\n",
        "    for w in word_tokens: \n",
        "        if w not in stopwords_ac: \n",
        "            filtered_sentence.append(w) \n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nah', 'I', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrb8-i4n_P-X"
      },
      "source": [
        "Here, we apply the clean_word method in order to remove punctuation and stopwords for all the sentences in the dataframe, then explore the most common words in the legitimate texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4LBpFdRtigb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a80b2ed0-22c9-4f9a-fe6c-1d16e9f43012"
      },
      "source": [
        "from collections import Counter\n",
        "sms[\"clean_msg\"] = sms.msg.apply(clean_word)\n",
        "words = sms[sms.label=='spam'].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\n",
        "\n",
        "ham_words = Counter()\n",
        "\n",
        "for msg in words:\n",
        "    ham_words.update(msg)\n",
        "\n",
        "print(ham_words.most_common(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('call', 347), ('free', 216), ('2', 173), ('txt', 150), ('u', 147)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cASsT8edwyLn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "39010deb-6b40-4ec5-c5f7-087d428f8867"
      },
      "source": [
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>msg</th>\n",
              "      <th>label_sign</th>\n",
              "      <th>clean_msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar Joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>U dun say early hor U c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>Nah I dont think goes usf lives around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                          clean_msg\n",
              "0   ham  ...  Go jurong point crazy Available bugis n great ...\n",
              "1   ham  ...                            Ok lar Joking wif u oni\n",
              "2  spam  ...  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
              "3   ham  ...                U dun say early hor U c already say\n",
              "4   ham  ...      Nah I dont think goes usf lives around though\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w9caVS-_aHM"
      },
      "source": [
        "We chose to use the sklearn library due to its simplicity and effectiveness in creating a simple Naive Bayes model. First, we split the dataset into training/testing sets respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERNqwkvhxQhQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "98ec3058-8169-4a8c-8418-78038e3358f6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(sms.clean_msg, sms.label_sign, random_state=1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4179,)\n",
            "(1393,)\n",
            "(4179,)\n",
            "(1393,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UizFHbKtADHa"
      },
      "source": [
        "We used a vectorizer to transform the training/testing sets into fitted vectors for model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TLzxqVo1gsM"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# instantiate the vectorizer\n",
        "vect = CountVectorizer()\n",
        "vect.fit(X_train)\n",
        "X_train_dim = vect.transform(X_train)\n",
        "X_test_dim = vect.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFde8TMoANlK"
      },
      "source": [
        "The result after using the multinomial Naive Bayes algorithm was a resounding success, with 98.6% accuracy! This is quite high however, and this may be the result of a fairly curated and commonly used dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptLz33hb0Be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6642fe30-e4fe-42cf-fdba-75903e7064d1"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "clf_mnb = MultinomialNB(alpha = 0.2)\n",
        "\n",
        "clf_mnb.fit(X_train_dim, y_train)\n",
        "\n",
        "y_test_pd = clf_mnb.predict(X_test_dim)\n",
        "metrics.accuracy_score(y_test, y_test_pd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9856424982053122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH1qx54EAavm"
      },
      "source": [
        "We dumped the model into a .joblib file for use in deploying in an API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW4tDsKTcVPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdcb658f-f791-4600-ec53-7b609ef20665"
      },
      "source": [
        "from joblib import dump, load\n",
        "dump(clf_mnb, 'filename.joblib') \n",
        "clf_mnb = load('filename.joblib') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['filename.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    }
  ]
}